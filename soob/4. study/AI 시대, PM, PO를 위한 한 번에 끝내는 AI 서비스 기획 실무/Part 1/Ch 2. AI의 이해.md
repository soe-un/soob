# 목차
```table-of-contents
title: 
style: nestedList # TOC style (nestedList|nestedOrderedList|inlineFirstLevel)
minLevel: 0 # Include headings from the specified level
maxLevel: 0 # Include headings up to the specified level
includeLinks: true # Make headings clickable
hideWhenEmpty: false # Hide TOC if no headings are found
debugInConsole: false # Print debug info in Obsidian console
```

# AI 모델의 종류

## 언어 모델 (Language Model)
- 앞 뒤 단어의 확률값을 계산해서 추정
- 모든 언어를 벡터화(숫자화)해서 언어의 의미를 파악하고 출력
### NLP (Natural Language Processing)
- 자연어를 처리하는 전체 과정 및 기술
#### NLU (Natural Language Understanding)
- 자연어를 이해하고 판단하는 과정 및 기술
#### NLG (Natural Language Generation)
- 적절한 자연어 답변을 생성하는 과정 및 기술

## 지식그래프 모델 (Knowledge Graph)
- 개별 객체간의 연관성 관계를 통해서 추론과 유추
- 관련된 정보를 모두 연관 그래프화

## 트리 모델
### 의사결정 트리
- 트리 구조로 이루어진 분류 및 회귀 모델
- 단순, 직관, 해석 가능성 높음 => 많은 분야에서 활용
- 데이터 특성에 따라 과적합 문제가 발생할 수 있어 주의 필요
### 랜덤 포레스트 모델
- 다수의 의사결정 트리를 앙상블하여 성능을 향상시킨 모델
- 분류, 회귀, 군집 등 다양한 문제에 적용 가능
- 과적합 문제를 해결하고 일반화 성능 우수
- 복잡한 데이터셋에서 강력한 성능
### 응용 분야
- 금융, 의료, 마케딩 등 다양한 분야에서 활용
- 결과의 해석이 중요한 경우에 특히 유용
- ex. 고객 세분화, 질병 진단, 신용 평가 등에 널리 사용

## SVM (Support Vector Machine)
### 원리
- 데이터 간의 최대 마진을 찾아 선형 분류
- 고차원 특징 공간에서 선형 분류기 학습을 통해 복잡한 문제도 해결가능

### 특징
- SVM은 소량의 데이터에서도 효과적으로 작동
- 고차원 데이터에 강점
- 추가 기법을 사용하면 복잡한 분류문제 가능

### 응용 분야
- 텍스트 분류, 이미지 인식, 생물정보학 등 다양한 분야에서 활용
- 특히 패턴 인식과 이상 탐지 문제에 뛰어난 성능

## KNN (K-최근접 이웃) 알고리즘 모델
### 원리
- 입력 데이터와 가장 유사한 K개의 이웃을 찾아 분류
- 단순하지만 효과적
- 주로 분류 문제에 사용
### 특징
- 구현이 간단
- 새로운 데이터에 대해 빠르게 예측 가능
- 데이터의 분포와 특성에 따라 성능이 크게 영향 받음
- 대규모 데이터셋에서는 계산 비용이 높아짐

### 응용 분야
- 추천 시스템, 패턴 인식, 이상 탐지 등 다양한 분야에서 활용
- 특히 데이터의 지역적 구조가 중요한 문제에서 효과적으로 사용


# AI 신경망 기술

*다층 퍼셉트론(Multilayer Perceptron) = AI 신경망*
## DNN(심층 신경망) 모델
### 구조
- 여러 개의 은닉층을 가지는 인공 신경망 모델
- 입력층, 여러 은닉층, 출력층으로 구성
- 각 층은 다수의 뉴런으로 구성
### 학습 과정
- 역전파 알고리즘
- 입력 데이터가 네트워크를 통과하면서 가중치가 조정되어 목표 출력과의 오차를 최소화
### 특징
- 복잡한 비선형 문제 해결 가능
- 이미지, 음성 ,텍스트 등 다양한 분야에 적용
- 많은 데이터와 계산 자원이 필요
- 높은 성능
### 응용
- 컴퓨터 비전, 자연어 처리, 음성 인식, 로봇 제어 등 광범위한 분야에서 활용
- 인공지능 발전의 핵심 기술
## CNN(합성곱 신경망) 모델
### 구조
- 이미지 처리에 특화된 DNN 모델
- 주요 구성 요소로 합성곱 층, 풀링 층, 완전 연결 층 존재
### 풀링
- 풀링층은 특징 맵의 크기를 줄이고 주요 특징을 보존함
- 풀링 과정을 통해 모델의 계산 효율성과 일반화 능력 향상
### 특징 추출
- CNN은 합성곱 연산을 통해 이미지의 지역적 특징을 추출
- 특징 추출 과정에서 필터를 사용하여 다양한 패턴을 학습
### 응용
- 이미지 분류, 객체 탐지, 세그멘테이션 등 컴퓨터 비전 분야
- 의료 영상 분석, 자율 주행 등으로 응용 범위 확대 중
## 시퀀스 데이터 처리 모델
### RNN (순환 신경망) 모델
- 시퀀스 데이터 처리에 특화된 DNN 모델
- 이전 출력이 현재 입력에 영향을 미치는 **순환 구조**
- 자연어 처리, 음성 인식, 시계열 데이터 분석 등에 활용
### LSTM (장단기 메모리) 모델
- RNN의 한계를 극복
- 장기 의존성 문제를 해결하기 위해 순환 처리하는 **정보의 양을 조절**
- 입력 게이트, 망각 게이트, 출력 게이트를 통해 정보의 흐름을 제어하고 장기 기억 유지
### 응용 분야
- 텍스트 생성, 기계 번역, 감성 분석, 음성 인식, 주가 예측 등 다양한 시퀀스 데이터 처리 분야
- LSTM은 긴 시퀀스 데이터에서 우수한 성능

## GAN (적대적 생성 신경망) 모델
### 구조
- 생성자(Generator)와 판별자(Discriminator) 두 개의 신경망으로 구성
- 생성사는 가짜 데이터를 생성
- 판별자는 가짜 데이터와 진짜 데이터를 구분하며 학습
### 학습 과정
- 생성자와 판별자가 서로 경쟁하며 학습
- 생성자는 점점 더 실제와 유사한 데이터를 생성
- 판별자는 더 정확한 구분을 위해 분류 특징 세분화
### 특징
- 실제 데이터와 구분하기 어려운 새로운 데이터 생성
- 높은 품질의 생성 결과물
- 비용이 많이 들고 시간이 많이 들어감(AI 모델 2개, 통신비, 조정이 어려움)
### 응용
- 이미지 생성, 텍스트 생성, 데이터 증강 등
- 창의적인 AI 응용 프로그램 개발에 중요한 역할

## Transformer 모델
*최신 Transformer 모델은 스스로 의미를 찾는
Self-Attention 기술,
Attention 기술
두 가지에 기반하고 있다.
: 사람의 직관을 흉내내기 위한 기술*
### 응용 분야
- 기계 번역: 한 언어에서 다른 언어로 텍스트 번역
- 문서 요약: 긴 문서의 핵심 내용을 요약
- 질문 응답: 주어진 질문에 대한 답변 생성
- 감성 분석: 텍스트의 감정이나 의견 분석
- 텍스트 생성:  주어진 프롬프트에 기반한 텍스트 생성

### Attention
1. 입력 시퀀스
	- 토큰화된 텍스트나 임베딩된 데이터를 모델에 입력
2. 어텐션 계산
	- 각 토큰 간 관련성을 계산하여 어텐션 스코어 생성
3. 컨텍스트 벡터 생성
	- 어텐션 스코어를 바탕으로 각 토큰에 대한 컨텍스트 벡터 생성
4. 출력 생성
	- 컨텍스트 벡터를 활용하여 최종 출력 생성
*입력 시퀀스 간의 모든 요소 간의 관계를 동시에 고려하고, 병렬 처리를 하여 계산*

### 인코더-디코더 구조
![[Pasted image 20250519162205.png]]
1. 인코더
	- 입력 시퀀스를 벡터화
	- 입력 시퀀스의 의미와 컨텍스트를 효과적으로 포착
2. 디코더
	- 인코더의 출력을 바탕으로 목표 시퀀스 생성
	- 자기회귀적 생성
	- 인코더-디코더 어텐션을 통해 입력 시퀀스의 정보 활용
3. 정보 흐름
	- 입력은 인코더를 통과하며 벡터화 변환
	- 디코더로 전달되어 출력 생성에 활용
	- 이러한 구조는 복잡한 시퀀스 변환 작업을 효과적으로 수행할 수 있게 도와줌

## 검색 증강 생성(RAG) 모델
*응답을 생성하기 전 신뢰할 수 있는 지식을 먼저 검색해 답변결과를 개선하는 기술*
### 특징
- 지식베이스 검색 기능
	- 대화 내용에 맞는 관련 정보를 지식베이스에서 검색하고 활용
	- 대화 내용의 정확정과 정보성을 확보
- 인코더-디코더 구조
	- RAG는 Transformer 기반의 인코더-디코더 구조
	- 인코더: 대화 내용 이해
	- 디코더: 지식베이스 정보 활용 답변 생성
-  지식베이스 통합
	- Wikipedia, Wikidata 등의 대규모 지식베이스와 통합
	- 다양한 주제에 대한 정보를 활용할 수 있도록 사내 정보시스템과 연계
- 문맥 인식 능력
	- 대화 맥락을 이해하고 관련 정보를 검색해 적절한 응답 생성
## 인간 피드백 강화학습(Reinforcement Learning fron Human Feedback, RLHF) 모델
### 기존 방식의 문제점
![[Pasted image 20250519163542.png]]
- 대규모 언어모델과 지식그래프에서 어떤 정보가 최우선되어야 하는지 모호한 문제
- 최신 기술인 대규모 언어모델을 사용했음에도 여전히 어색한 문장을 출력하는 한계점 발생
### 개선
![[Pasted image 20250519163701.png]]
- 기술 한계점을 보완하기 위해 인간 피드백 강화학습 단계 추가
- 인간의 피드백 값이 Reward Model 결과에 추가되어 더 현실적인 답변 생성
- 악의적인 피드백에 의한 방어 모델도 구축되어 있음
